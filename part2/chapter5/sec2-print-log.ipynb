{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "페이지 URL: http://example.com/1.page, HTP status:404,  처리 시간(초):0.552758\n",
      "페이지 URL: http://example.com/2.page, HTP status:404,  처리 시간(초):0.517445\n",
      "페이지 URL: http://example.com/3.page, HTP status:404,  처리 시간(초):0.50406\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time \n",
    "\n",
    "PAGE_URL_LIST = [\n",
    "    'http://example.com/1.page',\n",
    "    'http://example.com/2.page',\n",
    "    'http://example.com/3.page',\n",
    "]\n",
    "\n",
    "for page_url in PAGE_URL_LIST:\n",
    "    res = requests.get(page_url,timeout=30)\n",
    "    print(\n",
    "        '페이지 URL: {}, HTP status:{},  처리 시간(초):{}'.format(\n",
    "            page_url,\n",
    "            res.status_code,\n",
    "            res.elapsed.total_seconds()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": []
  },
  {
   "source": [
    "디버그 전용 로그와 오류 전용 로그를 다른 파일에 출력하면서 터미널의 포준 출력에도 로그를 출력하려면 바로 아래처럼 구현해야합니다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "크롤링을 시작합니다.\n",
      "\n",
      "[ERROR] 404 Client Error: Not Found for url: http://example.com/1.page\n",
      "\n",
      "[ERROR] 404 Client Error: Not Found for url: http://example.com/2.page\n",
      "\n",
      "[ERROR] 404 Client Error: Not Found for url: http://example.com/3.page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "PAGE_URL_LIST = [\n",
    "    'http://example.com/1.page',\n",
    "    'http://example.com/2.page',\n",
    "    'http://example.com/3.page',\n",
    "]\n",
    "\n",
    "def fetch_pages():\n",
    "    '''페이지의 내용을 추출합니다.'''\n",
    "    # 처리기록 전용 로그 파일을 append 모드로 엽니다.\n",
    "    f_info_log = open('crawler_info.log','a', encoding='utf-8')\n",
    "\n",
    "    # 오류기록 전용 로그 파일을 append mode로 엽니다.\n",
    "    f_error_log = open('crawler_error.log','a', encoding='utf-8')\n",
    "\n",
    "    # 추출 내용을 저장할 딕셔너리\n",
    "    page_contents = {}\n",
    "\n",
    "    # 터미널에 처리 시작을 출력하고, 로그 파일에도 메시지를 출력\n",
    "    msg = '크롤링을 시작합니다.\\n'\n",
    "    print(msg)\n",
    "    f_info_log.write(msg)\n",
    "    \n",
    "    for page_url in PAGE_URL_LIST:\n",
    "        r = requests.get(page_url, timeout=30)\n",
    "\n",
    "        try:\n",
    "            r.raise_for_status() # 응답에 에러 발생시 예외를 발생시킵니다.\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # requests와 관련된 예외가 발생하면\n",
    "            # 터미널과 오류 로그에 오류를 출력합니다. \n",
    "            msg = '[ERROR] {exception}\\n'.format(exception=e)\n",
    "            print(msg)\n",
    "            f_error_log.write(msg)\n",
    "            continue # 예외가 발생하면 반복을 중지하는게 아니라 건너 뜁니다.\n",
    "\n",
    "        # 정상적으로 내용을 추출했다면 딕셔너리에 내용을 저장합니다.page_url\n",
    "        page_contents[page_url] = r.text\n",
    "        time.sleep(1)\n",
    "\n",
    "    f_info_log.close()\n",
    "    f_error_log.close()\n",
    "\n",
    "    return page_contents\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    page_contents = fetch_pages()\n",
    "    f_page_contents = open('page_contents.json','w')\n",
    "    json.dump(page_contents, f_page_contents, ensure_ascii=False)\n",
    "    f_page_contents.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "```\n",
    "1. 파일 다루기 기본\n",
    "파이썬에서 파일 다룰 때는 기본 내장함수 open() 함수를 활용합니다.\n",
    "open() 함수의 사용법\n",
    "첫번째 인수 file경로만이 필수입니다.\n",
    "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)¶\n",
    "open() 함수 인자, 자주 사용하는 것만 살펴봅니다.\n",
    "\n",
    "file : 파일 경로\n",
    "mode : 파일이 열리는 모드\n",
    "'r' : 읽기 용으로 열림 (기본값)\n",
    "'w' : 쓰기 위해 열기, 파일을 먼저 자른다.\n",
    "'x' : 베타적 생성을 위해 열리고, 이미 존재하는 경우 실패\n",
    "'a' : 쓰기를 위해 열려 있고, 파일의 끝에 추가하는 경우 추가합니다.\n",
    "'b' : 2진 모드(바이너리 모드)\n",
    "'t' : 텍스트 모드 (기본값)\n",
    "'+' : 업데이트 (읽기 및 쓰기)를 위한 디스크 파일 열기\n",
    "'U' : 유니버설 개행 모드 (사용되지 않음)\n",
    "buffering : 버퍼링끄기는 0(바이너리모드에서만 동작함), 라인모드는 1 (텍스트 모드에서만 가능), 고정 크기로 보내려면 임의의 바이트수를 1보다 큰 양의 수로 입력, 기본 정책은 아래와 같습니다.\n",
    "이진 파일은 고정 크기 청크로 버퍼링됩니다. 버퍼의 크기는 기본 장치의 \"블록 크기\"를 결정하고 다시 떨어지는 경험적 방법을 사용하여 선택됩니다 io.DEFAULT_BUFFER_SIZE. 많은 시스템에서 버퍼는 일반적으로 4096 또는 8192 바이트 길이입니다.\n",
    "\"대화식\"텍스트 파일 ( isatty() 반환 되는 파일 True)은 회선 버퍼링을 사용합니다. 다른 텍스트 파일은 바이너리 파일에 대해 위에서 설명한 정책을 사용합니다.\n",
    "encoding : 파일을 디코딩하거나 인코딩하는데 사용되는 이름, 대부분 utf-8 이지만 모든 시스템이 utf-8이라는 보장이 없으므로 명시적으로 하는 것이 좋다.\n",
    "파이썬에서 지원되는 인코딩 목록 - https://docs.python.org/3.6/library/codecs.html\n",
    "파일 객체는 반드시 열고 작업이 완료되면 반드시 파일을 닫아야 합니다.\n",
    "\n",
    "파일을 닫지 않으면 버퍼링되어 있는 데이터는 기록되지 않고 소실될 수 있습니다.\n",
    "file 객체의 close()메소드로 파일을 닫습니다.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## with구문으로 close 메서드 누수 막기\n",
    "\n",
    "파일 개겣의 close 메서드 누수를 막을 수 있는 기능이 있습니다. 바로 with구문입니다.    \n",
    "with구문을 사용하면 with 구문 블록을 빠져나올 떄 close 메서드가 자동으로 호출됩니다. 또한 예외가 발생했을 떄도 close 메서드가 호출됩니다.    \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "크롤링을 시작합니다.\n",
      "\n",
      "[ERROR] 404 Client Error: Not Found for url: http://example.com/1.page.html\n",
      "\n",
      "[ERROR] 404 Client Error: Not Found for url: http://example.com/2.page.html\n",
      "\n",
      "[ERROR] 404 Client Error: Not Found for url: http://example.com/3.page.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "PAGE_URL_LIST = [\n",
    "    'http://example.com/1.page.html',\n",
    "    'http://example.com/2.page.html',\n",
    "    'http://example.com/3.page.html',\n",
    "]\n",
    "\n",
    "def fetch_pages():\n",
    "    '''페이지의 내용을 추출합니다.'''\n",
    "    # 처리기록 전용 로그 파일을 append 모드로 엽니다.\n",
    "    with open('crawler_info.log','a', encoding='utf-8')as f_info_log, \\\n",
    "        open('crawler_error.log','a', encoding='utf-8')as f_error_log:\n",
    "\n",
    "        # 추출 내용을 저장할 딕셔너리\n",
    "        page_contents = {}\n",
    "\n",
    "        # 터미널에 처리 시작을 출력하고, 로그 파일에도 메시지를 출력\n",
    "        msg = '크롤링을 시작합니다.\\n'\n",
    "        print(msg)\n",
    "        f_info_log.write(msg)\n",
    "        \n",
    "        for page_url in PAGE_URL_LIST:\n",
    "            try:\n",
    "                r = requests.get(page_url, timeout=30)\n",
    "                r.raise_for_status() # 응답에 에러 발생시 예외를 발생시킵니다.\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # requests와 관련된 예외가 발생하면\n",
    "                # 터미널과 오류 로그에 오류를 출력합니다. \n",
    "                msg = '[ERROR] {exception}\\n'.format(exception=e)\n",
    "                print(msg)\n",
    "                f_error_log.write(msg)\n",
    "                continue # 예외가 발생하면 반복을 중지하는게 아니라 건너 뜁니다.\n",
    "\n",
    "            # 정상적으로 내용을 추출했다면 딕셔너리에 내용을 저장합니다.page_url\n",
    "            page_contents[page_url] = r.text\n",
    "            time.sleep(1)\n",
    "\n",
    "        return page_contents\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    page_contents = fetch_pages()\n",
    "    f_page_contents = open('page_contents.json','w')\n",
    "    with open('page_contents.json', 'w', encoding='utf8') as f_page_contents:\n",
    "        json.dump(page_contents, f_page_contents, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}